{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 77760 243 320\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# path to the database - change it if needed\n",
    "path = 'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week05\\\\data\\\\face_data\\\\face_data\\\\'\n",
    "\n",
    "ids = range(1, 16) # 15 people\n",
    "states = ['centerlight', 'glasses', 'happy', 'leftlight','noglasses', 'normal', 'rightlight','sad','sleepy', 'surprised', 'wink' ]\n",
    "prefix = 'subject'\n",
    "surfix = '.png' #file extension is png\n",
    "\n",
    "# open one picture to get the image's size\n",
    "fn = prefix + '01.' + states[0] + surfix\n",
    "im = cv2.imread(path + fn, 0)\n",
    "\n",
    "h = im.shape[0] # hight\n",
    "w = im.shape[1] # width\n",
    "\n",
    "D = h * w\n",
    "N = len(states)*15\n",
    "print(N, D, h, w)\n",
    "\n",
    "X = np.zeros((D, N))\n",
    "\n",
    "# collect all data\n",
    "count = 0\n",
    "# there are 15 people\n",
    "for person_id in range(1, 16):\n",
    "    for state in states:\n",
    "        # get name of each image file\n",
    "        fn = path + prefix + str(person_id).zfill(2) + '.' + state + surfix\n",
    "        # open the file and read as grey image\n",
    "        tmp = cv2.imread(fn, cv2.IMREAD_GRAYSCALE)\n",
    "        # then add image to dataset X\n",
    "        X[:, count] = tmp.reshape(D)\n",
    "        count += 1\n",
    "        \n",
    "# Tạo mảng y chứa nhãn cho mỗi mẫu dữ liệu\n",
    "# Khởi tạo mảng y\n",
    "y = np.zeros(165)\n",
    "# Chuyển y thành mảng numpy để sử dụng trong train_test_split\n",
    "y = states * 15\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Áp dụng cho dữ liệu ảnh khuôn mặt (của 15 người, mỗi người có 11 trạng thái):\n",
    "\n",
    "a. Giảm số chiều dữ liệu xuống còn 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (77760, 165)\n",
      "Shape after PCA: (165, 50)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Initialize PCA with n_components = min(n_samples, n_features)\n",
    "pca = PCA(50)\n",
    "\n",
    "# Fit PCA to the data X\n",
    "X_pca = pca.fit_transform(X.T)  # Transpose X to fit PCA (samples as rows, features as columns)\n",
    "\n",
    "print(\"Original shape:\", X.shape)\n",
    "print(\"Shape after PCA:\", X_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Multinomial Logistic Regression: 0.16\n",
      "Accuracy of Naïve Bayes: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Multinomial Logistic Regression\n",
    "logistic_regression = LogisticRegression(multi_class='multinomial', solver='sag', max_iter=5000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
    "print(\"Accuracy of Multinomial Logistic Regression:\", accuracy_lr)\n",
    "\n",
    "# Naïve Bayes\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "print(\"Accuracy of Naïve Bayes:\", accuracy_nb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels using Multinomial Logistic Regression: ['noglasses' 'noglasses' 'noglasses' 'leftlight' 'noglasses']\n",
      "Predicted labels using Naïve Bayes: ['sleepy' 'normal' 'normal' 'rightlight' 'normal']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Load and preprocess the new images\n",
    "new_image_paths = ['D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week05\\\\data\\\\face_data\\\\face_data\\\\subject01.centerlight.png',\n",
    "                   'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week05\\\\data\\\\face_data\\\\face_data\\\\subject01.glasses.png',\n",
    "                   'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week05\\\\data\\\\face_data\\\\face_data\\\\subject01.happy.png',\n",
    "                   'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week05\\\\data\\\\face_data\\\\face_data\\\\subject01.leftlight.png',\n",
    "                   'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week05\\\\data\\\\face_data\\\\face_data\\\\subject01.normal.png']\n",
    "new_images = []\n",
    "for path in new_image_paths:\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Resize image to match the dimensions of the original dataset\n",
    "    img_resized = cv2.resize(img, (243, 320))\n",
    "    new_images.append(img_resized.flatten())  # Flatten image to match the shape of data for PCA\n",
    "\n",
    "# Convert new images to numpy array\n",
    "X_new = np.array(new_images)\n",
    "\n",
    "# Transform new images using the PCA model trained on the original dataset\n",
    "X_new_pca = pca.transform(X_new)\n",
    "\n",
    "# Use the trained model to predict labels for the new images\n",
    "y_pred_lr_new = logistic_regression.predict(X_new_pca)\n",
    "y_pred_nb_new = naive_bayes.predict(X_new_pca)\n",
    "\n",
    "# Print predicted labels for the new images\n",
    "print(\"Predicted labels using Multinomial Logistic Regression:\", y_pred_lr_new)\n",
    "print(\"Predicted labels using Naïve Bayes:\", y_pred_nb_new)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
