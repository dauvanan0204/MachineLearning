{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(\"D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week03\\\\data\\\\framingham.csv\")\n",
    "data.isnull().sum()\n",
    "data = data.dropna(how=\"any\", axis=0)\n",
    "\n",
    "male = data['male'].tolist() \n",
    "X1 = np.asarray(male) \n",
    "\n",
    "age = data['age'].tolist() \n",
    "X2 = np.asarray(age) \n",
    "\n",
    "education = data['education'].tolist() \n",
    "X3 = np.asarray(education) \n",
    "\n",
    "currentSmoker = data['currentSmoker'].tolist() \n",
    "X4 = np.asarray(currentSmoker) \n",
    "\n",
    "cigsPerDay = data['cigsPerDay'].tolist() \n",
    "X5 = np.asarray(cigsPerDay) \n",
    "\n",
    "BPMeds = data['BPMeds'].tolist() \n",
    "X6 = np.asarray(BPMeds) \n",
    "\n",
    "prevalentStroke = data['prevalentStroke'].tolist() \n",
    "X7 = np.asarray(prevalentStroke) \n",
    "\n",
    "prevalentHyp = data['prevalentHyp'].tolist() \n",
    "X8 = np.asarray(prevalentHyp) \n",
    "\n",
    "diabetes = data['diabetes'].tolist() \n",
    "X9 = np.asarray(diabetes) \n",
    "\n",
    "totChol = data['totChol'].tolist() \n",
    "X10 = np.asarray(totChol) \n",
    "\n",
    "sysBP = data['sysBP'].tolist() \n",
    "X11 = np.asarray(sysBP) \n",
    "\n",
    "diaBP = data['diaBP'].tolist() \n",
    "X12 = np.asarray(diaBP) \n",
    "\n",
    "BMI = data['BMI'].tolist() \n",
    "X13 = np.asarray(BMI) \n",
    "\n",
    "heartRate = data['heartRate'].tolist() \n",
    "X14 = np.asarray(heartRate) \n",
    "\n",
    "glucose = data['glucose'].tolist() \n",
    "X15 = np.asarray(glucose) \n",
    "\n",
    "TenYearCHD = data['TenYearCHD'].tolist() \n",
    "y = np.asarray(TenYearCHD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s, clip_threshold=20):\n",
    "    clipped_s = np.clip(s, -clip_threshold, clip_threshold)\n",
    "    return 1 / (1 + np.exp(-clipped_s))\n",
    "\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol = 1e-4, max_count = 10000): \n",
    "# method to calculate model logistic regression by Stochastic Gradient Descent method \n",
    "# eta: learning rate; tol: tolerance; max_count: maximum iterates \n",
    "    w = [w_init]     \n",
    "    it = 0 \n",
    "    N = X.shape[1] \n",
    "    d = X.shape[0] \n",
    "    count = 0 \n",
    "    check_w_after = 20\n",
    "# loop of stochastic gradient descent  \n",
    "    while count < max_count: \n",
    "        # shuffle the order of data (for stochastic gradient descent).  \n",
    "        # and put into mix_id  \n",
    "        mix_id = np.random.permutation(N) \n",
    "        for i in mix_id: \n",
    "            xi = X[:, i].reshape(d, 1) \n",
    "            yi = y[i] \n",
    "            zi = sigmoid(np.dot(w[-1].T, xi)) \n",
    "            w_new = w[-1] + eta*(yi - zi)*xi \n",
    "            count += 1 \n",
    "            # stopping criteria \n",
    "            if count%check_w_after == 0:                 \n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol: \n",
    "                    return w \n",
    "            w.append(w_new) \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.58375355]\n",
      " [  2.04318687]\n",
      " [  2.84543659]\n",
      " [ -0.59905614]\n",
      " [ -0.65911161]\n",
      " [  2.78880003]\n",
      " [ -0.4875276 ]\n",
      " [  0.04440762]\n",
      " [  0.89186609]\n",
      " [  0.10727018]\n",
      " [ -3.10757965]\n",
      " [ 15.99865144]\n",
      " [ -9.28425757]\n",
      " [ -5.4370611 ]\n",
      " [-29.02691289]\n",
      " [  7.27135972]]\n"
     ]
    }
   ],
   "source": [
    "eta = .05  \n",
    "d = X.shape[0] \n",
    "w_init = np.random.randn(d, 1) \n",
    " \n",
    "w = logistic_sigmoid_regression(X, y, w_init, eta) \n",
    "print(w[-1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.06115362e-09 2.06115362e-09 2.06115362e-09 ... 2.06115362e-09\n",
      "  2.06115362e-09 2.06115362e-09]]\n",
      "[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sigmoid_outputs = sigmoid(np.dot(w[-1].T, X))\n",
    "print(sigmoid_outputs)\n",
    "# Phân loại các giá trị\n",
    "classified_values = np.where(sigmoid_outputs >= 0.5, 1, 0)\n",
    "\n",
    "print(classified_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3656)\n",
      "(3656,)\n",
      "(2559, 16)\n",
      "[0 0 0 ... 0 0 0]\n",
      "[[-4.45421377e-01  5.39434719e-01  2.89174521e-02 -2.08755675e-01\n",
      "  -1.80837474e-01  2.11505072e-02  2.28399793e-01  1.19907984e-01\n",
      "   1.01104522e+00  2.33196289e-01  2.16478040e-04  1.11156726e-02\n",
      "  -1.75255841e-02 -5.14573154e-02 -2.53711553e-02  5.47060324e-03]]\n",
      "Accuracy: 0.8468550592525068\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.06896551724137931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FPT SHOP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Sử dụng thư viện scikit-learn \n",
    "from sklearn import linear_model \n",
    "logReg = linear_model.LogisticRegression(penalty=None) \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Add a column of ones to the left of the matrix X to get Xbar\n",
    "N = X1.shape[0]\n",
    "X = np.array([np.ones((N)), X1.T, X2.T, X3.T, X4.T, X5.T, X6.T, X7.T, X8.T, X9.T, X10.T, X11.T, X12.T, X13.T, X14.T, X15.T])\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "# Assuming X and y are your feature matrix and target vector\n",
    "X_train, X_val, y_train, y_val = train_test_split(X.T, y, test_size=0.3, random_state=42)\n",
    "logReg.fit(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "# # Prediction\n",
    "predict = logReg.predict(X_val) \n",
    "print(predict)\n",
    "# For showing of w \n",
    "print(logReg.coef_)\n",
    "\n",
    "# Tính toán Accuracy\n",
    "accuracy = accuracy_score(y_val, predict)\n",
    "\n",
    "# Tính toán Precision\n",
    "precision = precision_score(y_val, predict)\n",
    "\n",
    "# Tính toán Recall\n",
    "recall = recall_score(y_val, predict)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
