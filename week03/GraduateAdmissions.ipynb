{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module \n",
    "import numpy as np \n",
    "from pandas import * \n",
    "# reading CSV file \n",
    "data = read_csv(\".\\data\\Admission_Predict.csv\") \n",
    "# converting column data to list, then convert list to array \n",
    "\n",
    "sn = data['Serial No.'].tolist() \n",
    " \n",
    "gre = data['GRE Score'].tolist() \n",
    "X1 = np.asarray(gre) \n",
    " \n",
    "tfl = data['TOEFL Score'].tolist() \n",
    "X2 = np.asarray(tfl) \n",
    " \n",
    "unirt = data['University Rating'].tolist() \n",
    "X3 = np.asarray(unirt) \n",
    " \n",
    "sop = data['SOP'].tolist() \n",
    "X4 = np.asarray(sop) \n",
    " \n",
    "lor1 = data['LOR '].tolist() \n",
    "X5 = np.asarray(lor1) \n",
    " \n",
    "cgpa1 = data['CGPA'].tolist() \n",
    "X6 = np.asarray(cgpa1) \n",
    "  \n",
    "research_exp = data['Research'].tolist() \n",
    "X7 = np.asarray(research_exp) \n",
    " \n",
    "prob_Admit = data['Chance of Admit'].tolist() \n",
    "Yt = np.asarray(prob_Admit)\n",
    "y = np.where(Yt >= 0.75, 1, 0)\n",
    "# y = Yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(s, clip_threshold=20):\n",
    "    clipped_s = np.clip(s, -clip_threshold, clip_threshold)\n",
    "    return 1 / (1 + np.exp(-clipped_s))\n",
    "\n",
    "def logistic_sigmoid_regression(X, y, w_init, eta, tol = 1e-4, max_count = 10000): \n",
    "# method to calculate model logistic regression by Stochastic Gradient Descent method \n",
    "# eta: learning rate; tol: tolerance; max_count: maximum iterates \n",
    "    w = [w_init]     \n",
    "    it = 0 \n",
    "    N = X.shape[1] \n",
    "    d = X.shape[0] \n",
    "    count = 0 \n",
    "    check_w_after = 350\n",
    "# loop of stochastic gradient descent  \n",
    "    while count < max_count: \n",
    "        # shuffle the order of data (for stochastic gradient descent).  \n",
    "        # and put into mix_id  \n",
    "        mix_id = np.random.permutation(N) \n",
    "        for i in mix_id: \n",
    "            xi = X[:, i].reshape(d, 1) \n",
    "            yi = y[i] \n",
    "            zi = sigmoid(np.dot(w[-1].T, xi)) \n",
    "            w_new = w[-1] + eta*(yi - zi)*xi \n",
    "            count += 1 \n",
    "            # stopping criteria \n",
    "            if count%check_w_after == 0:                 \n",
    "                if np.linalg.norm(w_new - w[-check_w_after]) < tol: \n",
    "                    return w \n",
    "            w.append(w_new) \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "[[-1.58794111]\n",
      " [-6.60561159]\n",
      " [22.26488592]\n",
      " [16.34913651]\n",
      " [ 9.99142864]\n",
      " [10.64191217]\n",
      " [ 4.78463071]\n",
      " [ 4.8882386 ]]\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1 1 1]]\n",
      "Accuracy: 0.44\n",
      "Precision: 0.44\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Add a column of ones to the left of the matrix X to get Xbar\n",
    "N = X1.shape[0]\n",
    "X = np.array([np.ones((N)), X1.T, X2.T, X3.T, X4.T, X5.T, X6.T, X7.T])\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "X_train = X[:, :350]\n",
    "# print(X_train.shape)\n",
    "y_train = y[:350]\n",
    "\n",
    "# Applying logistic sigmoid regression to find coefficients\n",
    "w_init = np.random.randn(X_train.shape[0], 1)\n",
    "eta = 0.005\n",
    "w = logistic_sigmoid_regression(X_train, y_train, w_init, eta)\n",
    "\n",
    "# Print coefficients\n",
    "print(\"Coefficients:\")\n",
    "print(w[-1])\n",
    "\n",
    "sigmoid_outputs = sigmoid(np.dot(w[-1].T, X_train))\n",
    "# print(sigmoid_outputs)\n",
    "h = np.where(sigmoid_outputs >= 0.75, 1, 0)\n",
    "print(h)\n",
    "\n",
    "# # Prediction\n",
    "X_test = X[:, 350:]\n",
    "y_test = y[350:]\n",
    "# print(X_test.shape)\n",
    "predictions = sigmoid(np.dot(w[-1].T, X_test ))\n",
    "# print(predictions)\n",
    "pre = np.where(predictions >= 0.75, 1, 0)\n",
    "print(pre)\n",
    "predicted_labels = (predictions >= 0.75).astype(int)\n",
    "\n",
    "# Comparison with actual labels\n",
    "actual_labels = (y_test >= 0.75).astype(int)\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = np.mean(predicted_labels == actual_labels)\n",
    "precision = np.sum((predicted_labels == 1) & (actual_labels == 1)) / np.sum(predicted_labels == 1)\n",
    "recall = np.sum((predicted_labels == 1) & (actual_labels == 1)) / np.sum(actual_labels == 1)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.09589505693113347\n",
      "Linear Regression Accuracy: 0.9\n",
      "Linear Regression Precision: 0.9473684210526315\n",
      "Linear Regression Recall: 0.8181818181818182\n",
      "Linear Regression Training Time: 0.0025510787963867188\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "\n",
    "# Tạo một mô hình hồi quy tuyến tính\n",
    "linear_reg = LinearRegression()\n",
    "\n",
    "# Huấn luyện mô hình trên tập huấn luyện\n",
    "start_time = time.time()\n",
    "linear_reg.fit(X_train.T, y_train)\n",
    "end_time = time.time()\n",
    "ln_training_time = end_time - start_time\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "y_pred = linear_reg.predict(X_test.T)\n",
    "\n",
    "# Tính toán bình phương sai số\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Độ chính xác của Linear Model\n",
    "accuracy_ln = accuracy_score(y_test, y_pred.round())\n",
    "precision_ln = precision_score(y_test, y_pred.round())\n",
    "recall_ln = recall_score(y_test, y_pred.round())\n",
    "\n",
    "# In ra kết quả\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Linear Regression Accuracy:\", accuracy_ln)\n",
    "print(\"Linear Regression Precision:\", precision_ln)\n",
    "print(\"Linear Regression Recall:\", recall_ln)\n",
    "print(\"Linear Regression Training Time:\", ln_training_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naïve Bayes Accuracy: 0.9\n",
      "Naïve Bayes Precision: 0.9473684210526315\n",
      "Naïve Bayes Recall: 0.8181818181818182\n",
      "Naïve Bayes Training Time: 0.013684511184692383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "import time\n",
    "\n",
    "# Xây dựng mô hình Naïve Bayes\n",
    "naive_bayes_model = GaussianNB()\n",
    "\n",
    "# Huấn luyện mô hình Naïve Bayes\n",
    "start_time = time.time()\n",
    "naive_bayes_model.fit(X_train.T, y_train)\n",
    "end_time = time.time()\n",
    "nb_training_time = end_time - start_time\n",
    "\n",
    "# Dự đoán nhãn cho tập kiểm tra\n",
    "y_pred_nb = naive_bayes_model.predict(X_test.T)\n",
    "\n",
    "# Độ chính xác của Naïve Bayes\n",
    "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "precision_nb = precision_score(y_test, y_pred_nb)\n",
    "recall_nb = recall_score(y_test, y_pred_nb)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Naïve Bayes Accuracy:\", accuracy_nb)\n",
    "print(\"Naïve Bayes Precision:\", precision_nb)\n",
    "print(\"Naïve Bayes Recall:\", recall_nb)\n",
    "print(\"Naïve Bayes Training Time:\", nb_training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0\n",
      " 0 0 0 0 0 1 0 1 1 1 1 0 1]\n",
      "[[-0.90332111 -0.12045138  0.06158672  0.83869528  0.48260622  0.286543\n",
      "   3.08759068  1.9931046 ]]\n",
      "Accuracy: 0.88\n",
      "Precision: 0.9444444444444444\n",
      "Recall: 0.7727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FPT SHOP\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Sử dụng thư viện scikit-learn \n",
    "from sklearn import linear_model \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "logReg = linear_model.LogisticRegression(penalty=None) \n",
    "N = X1.shape[0]\n",
    "X = np.array([np.ones((N)), X1.T, X2.T, X3.T, X4.T, X5.T, X6.T, X7.T])\n",
    "# print(X.shape)\n",
    "X_train = X[:, :350]\n",
    "# print(X_train.shape)\n",
    "y_train = y[:350]\n",
    "logReg.fit(X_train.T, y_train)\n",
    "# # Prediction\n",
    "X_test = X[:, 350:]\n",
    "y_test = y[350:]\n",
    "predict = logReg.predict(X_test.T) \n",
    "print(predict)\n",
    "# For showing of w \n",
    "print(logReg.coef_)\n",
    "\n",
    "\n",
    "# Tính toán Accuracy\n",
    "accuracy = accuracy_score(y_test, predict)\n",
    "\n",
    "# Tính toán Precision\n",
    "precision = precision_score(y_test, predict)\n",
    "\n",
    "# Tính toán Recall\n",
    "recall = recall_score(y_test, predict)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
