{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jKQsoSw4Cd6s"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "import PIL\n",
        "import PIL.Image\n",
        "from tensorflow import keras\n",
        "import tensorflow_datasets as tfds\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_animals():\n",
        "# Creates an instance of an ImageDataGenerator called train_datagen, and a train_generator, train_datagen.flow_from_directory\n",
        "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "  #splits data into training and testing(validation) sets\n",
        "  train_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  images_per_class_train = 750\n",
        "  images_per_class_test = 250\n",
        "\n",
        "  #training data\n",
        "  train_generator = train_datagen.flow_from_directory('/content/CNN_MultiClass_data/animals',\n",
        "  # Source directory\n",
        "    target_size=(150, 150), # Resizes images\n",
        "    batch_size=images_per_class_train,\n",
        "    class_mode='categorical',subset = 'training', shuffle=True)\n",
        "  #Testing data\n",
        "  validation_generator = train_datagen.flow_from_directory('/content/CNN_MultiClass_data/validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=images_per_class_test,\n",
        "    class_mode='categorical',\n",
        "    subset='validation', shuffle=True) # set as validation data\n",
        "\n",
        "  # Lấy ảnh và nhãn từ tập dữ liệu\n",
        "  train_images, labels_train = next(train_generator)\n",
        "  test_images, labels_test = next(validation_generator)\n",
        "\n",
        "  return train_images, test_images, labels_train, labels_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_animals()"
      ],
      "metadata": {
        "id": "5YzHeiBKFuSW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c1a439-961c-4984-acaf-f82567e0db2c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2250 images belonging to 3 classes.\n",
            "Found 750 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Đưa ảnh về dạng vecto"
      ],
      "metadata": {
        "id": "KOSgPrS2dwAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "y_train = np.argmax(y_train, axis=1)\n",
        "y_test = np.argmax(y_test, axis=1)"
      ],
      "metadata": {
        "id": "QVQqzRhaJeKx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression"
      ],
      "metadata": {
        "id": "SjLQ1fKJeDvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2kQn_VHeILA",
        "outputId": "8e7af576-22c9-43ba-e5d4-0fd5f9562921"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ANN\n",
        "Giảm dữ liệu xuống 225 chiều"
      ],
      "metadata": {
        "id": "xVdg_Utoek1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=225)\n",
        "pca.fit(X_train)\n",
        "\n",
        "X_train_pca = pca.transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "HWeLGq_SfMPe"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape = (225,)))\n",
        "model.add(Dense(128,activation = 'relu'))\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(Dense(32,activation = 'relu'))\n",
        "model.add(Dense(10,activation = 'softmax'))\n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = 'Adam',\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "model.fit(X_train_pca,y_train,epochs= 4 , validation_split = .2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-ygrIhPJD6W",
        "outputId": "224e01cb-9224-4c17-c9fe-69f9f528aeec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "19/19 [==============================] - 4s 58ms/step - loss: 1.9900 - accuracy: 0.2867 - val_loss: 1.4368 - val_accuracy: 0.3800\n",
            "Epoch 2/4\n",
            "19/19 [==============================] - 0s 14ms/step - loss: 1.0056 - accuracy: 0.5700 - val_loss: 1.2412 - val_accuracy: 0.4200\n",
            "Epoch 3/4\n",
            "19/19 [==============================] - 0s 16ms/step - loss: 0.6510 - accuracy: 0.7617 - val_loss: 1.2068 - val_accuracy: 0.4600\n",
            "Epoch 4/4\n",
            "19/19 [==============================] - 0s 12ms/step - loss: 0.4626 - accuracy: 0.8567 - val_loss: 1.2562 - val_accuracy: 0.4533\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f739995fcd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_pca)\n",
        "y_pred = y_pred.argmax(axis = 1)\n",
        "print(y_pred)\n",
        "\n",
        "accuracy = accuracy_score(y_pred, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDc2Y-siJIfd",
        "outputId": "e2d2d7bd-5190-4ed7-b68c-b76f4e9ae896"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 5ms/step\n",
            "[1 0 0 1 0 0 0 1 1 1 2 1 2 2 2 0 1 2 2 0 0 0 0 0 1 2 0 0 2 1 2 0 2 1 0 0 1\n",
            " 0 0 2 2 2 0 2 0 2 0 0 1 0 2 0 0 2 2 2 0 1 2 0 0 0 2 0 1 0 1 2 1 1 2 1 0 1\n",
            " 2 0 1 0 0 1 0 0 2 0 0 0 2 1 0 1 2 1 2 0 1 0 1 0 0 2 2 1 0 0 0 2 0 1 0 2 1\n",
            " 0 0 2 2 1 2 1 1 2 0 2 1 2 0 0 0 2 0 2 2 2 0 0 2 0 1 0 1 1 1 2 0 2 2 2 0 1\n",
            " 0 2 0 1 1 2 0 0 1 0 0 0 0 1 0 2 0 0 0 1 0 0 0 0 0 1 1 1 0 2 0 1 2 1 1 2 2\n",
            " 1 0 2 1 0 0 1 0 0 1 2 1 2 1 2 1 2 1 1 0 0 1 0 2 2 1 0 0 2 1 1 0 2 0 1 2 1\n",
            " 0 0 0 2 1 2 1 1 0 1 1 2 0 2 1 1 0 2 0 1 1 1 0 0 2 2 2 1]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN"
      ],
      "metadata": {
        "id": "URXba0ygKulw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_animals():\n",
        "# Creates an instance of an ImageDataGenerator called train_datagen, and a train_generator, train_datagen.flow_from_directory\n",
        "  from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "  #splits data into training and testing(validation) sets\n",
        "  train_datagen =ImageDataGenerator(rescale=1./255, validation_split=0.25)\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  images_per_class_train = 750\n",
        "  images_per_class_test = 250\n",
        "\n",
        "  #training data\n",
        "  train_generator = train_datagen.flow_from_directory('/content/CNN_MultiClass_data/animals',\n",
        "  # Source directory\n",
        "    target_size=(150, 150), # Resizes images\n",
        "    batch_size=images_per_class_train,\n",
        "    class_mode='categorical',subset = 'training', shuffle=True)\n",
        "  #Testing data\n",
        "  validation_generator = train_datagen.flow_from_directory('/content/CNN_MultiClass_data/validation',\n",
        "    target_size=(150, 150),\n",
        "    batch_size=images_per_class_test,\n",
        "    class_mode='categorical',\n",
        "    subset='validation', shuffle=True) # set as validation data\n",
        "\n",
        "  # Lấy ảnh và nhãn từ tập dữ liệu\n",
        "  train_images, labels_train = next(train_generator)\n",
        "  test_images, labels_test = next(validation_generator)\n",
        "\n",
        "  return train_images, test_images, labels_train, labels_test\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_animals()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OowmSb-MKmYk",
        "outputId": "dee19550-479f-45a7-8b98-61f053a2fa26"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2250 images belonging to 3 classes.\n",
            "Found 750 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chuẩn bị dữ liệu train, test để phân loại 2 lớp chó, mèo"
      ],
      "metadata": {
        "id": "bfV3rvKXJUsp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data(images, labels, class_indices, num_images):\n",
        "  filtered_images = []\n",
        "  filtered_labels = []\n",
        "  for i, label in enumerate(labels):\n",
        "    if label[class_indices[0]] == 1 or label[class_indices[1]] == 1:\n",
        "      filtered_images.append(images[i])\n",
        "      if label[class_indices[0]] == 1:\n",
        "        filtered_labels.append(0)  # Nhãn cho lớp 0\n",
        "      else:\n",
        "        filtered_labels.append(1)  # Nhãn cho lớp 1\n",
        "      num_images -= 1\n",
        "      if num_images == 0:\n",
        "        break\n",
        "  return np.array(filtered_images), np.array(filtered_labels)\n",
        "\n",
        "class_indices = [0, 1]\n",
        "\n",
        "X_train, y_train = get_data(X_train, y_train, class_indices, 150)\n",
        "\n",
        "X_test, y_test = get_data(X_test, y_test, class_indices, 100)"
      ],
      "metadata": {
        "id": "efViYpUYJ2El"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),  # Tầng Dropout với tỷ lệ dropout là 0.3\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),  # Tầng Dropout với tỷ lệ dropout là 0.4\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.5),  # Tầng Dropout với tỷ lệ dropout là 0.5\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # 2 lớp đầu ra với softmax activation\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "pi2MDVSJKySD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixDYMo2uK47-",
        "outputId": "616854fd-2fb2-45df-9c12-283042dc5c1c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 10s 2s/step - loss: 1.9196 - accuracy: 0.4733 - val_loss: 0.6939 - val_accuracy: 0.4200\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6944 - accuracy: 0.5000 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.6915 - accuracy: 0.5400 - val_loss: 0.6933 - val_accuracy: 0.4900\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6907 - accuracy: 0.5400 - val_loss: 0.6934 - val_accuracy: 0.4900\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.6901 - accuracy: 0.5400 - val_loss: 0.6935 - val_accuracy: 0.4900\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.6922 - accuracy: 0.5400 - val_loss: 0.6941 - val_accuracy: 0.4900\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.6909 - accuracy: 0.5400 - val_loss: 0.6943 - val_accuracy: 0.4900\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 7s 2s/step - loss: 0.6939 - accuracy: 0.5400 - val_loss: 0.6949 - val_accuracy: 0.4900\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.6889 - accuracy: 0.5400 - val_loss: 0.6942 - val_accuracy: 0.4900\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 10s 2s/step - loss: 0.6903 - accuracy: 0.5400 - val_loss: 0.6940 - val_accuracy: 0.4900\n",
            "4/4 [==============================] - 1s 238ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(2, activation='softmax')  # 2 lớp đầu ra với softmax activation\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "gn0dMICmLQz-"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo4Df0suLUBd",
        "outputId": "47862ab8-453e-4719-a526-9b80a0868316"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "5/5 [==============================] - 9s 2s/step - loss: 0.8904 - accuracy: 0.4667 - val_loss: 0.6933 - val_accuracy: 0.5100\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.6976 - accuracy: 0.4667 - val_loss: 0.6924 - val_accuracy: 0.5300\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.7006 - accuracy: 0.5133 - val_loss: 0.6928 - val_accuracy: 0.5300\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.6897 - accuracy: 0.6467 - val_loss: 0.6929 - val_accuracy: 0.4900\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.6854 - accuracy: 0.6333 - val_loss: 0.6915 - val_accuracy: 0.5200\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.6682 - accuracy: 0.6133 - val_loss: 0.6817 - val_accuracy: 0.5800\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 7s 1s/step - loss: 0.6319 - accuracy: 0.7067 - val_loss: 0.7164 - val_accuracy: 0.5000\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.5627 - accuracy: 0.7467 - val_loss: 0.6551 - val_accuracy: 0.6000\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 8s 2s/step - loss: 0.4702 - accuracy: 0.8133 - val_loss: 0.8787 - val_accuracy: 0.4900\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.4193 - accuracy: 0.8000 - val_loss: 0.7190 - val_accuracy: 0.5600\n",
            "4/4 [==============================] - 1s 229ms/step\n"
          ]
        }
      ]
    }
  ]
}