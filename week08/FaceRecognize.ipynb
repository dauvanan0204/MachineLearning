{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165 77760 243 320\n"
     ]
    }
   ],
   "source": [
    "# Xuất thư viện\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Đường dẫn tuyệt đối\n",
    "path = \"E:\\\\Machine learning\\\\Data\\\\face_data\\\\\"\n",
    "ids = range(1, 16) # 15 people\n",
    "states = ['centerlight', 'glasses', 'happy', 'leftlight', \n",
    "          'noglasses', 'normal', 'rightlight','sad', \n",
    "          'sleepy', 'surprised', 'wink' ]\n",
    "prefix = 'subject'\n",
    "surfix = '.png'     #file extension is png\n",
    "\n",
    "# open one picture to get the image's size\n",
    "fn = prefix + '01.' + states[0] + surfix\n",
    "im = cv2.imread(path + fn, 0)\n",
    "h = im.shape[0] # hight \n",
    "w = im.shape[1] # width\n",
    "D = h * w\n",
    "N = len(states)*15\n",
    "print(N, D, h, w)\n",
    "X = np.zeros((D, N))\n",
    "\n",
    "# Tạo nhãn cho dữ liệu, giả sử có 15 người và 11 biểu cảm cho mỗi người\n",
    "y = np.repeat(range(1, 16), len(states))\n",
    "\n",
    "# collect all data\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[130. 130. 130. ... 130. 130. 130.]\n",
      " [130. 130. 130. ... 130. 130. 130.]\n",
      " [130. 130. 130. ... 130. 130. 130.]\n",
      " ...\n",
      " [ 68.  68.  68. ...  68.  68.  68.]\n",
      " [ 68.  68.  68. ...  68.  68.  68.]\n",
      " [ 68.  68.  68. ...  68.  68.  68.]]\n",
      "['centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink', 'centerlight', 'glasses', 'happy', 'leftlight', 'noglasses', 'normal', 'rightlight', 'sad', 'sleepy', 'surprised', 'wink']\n"
     ]
    }
   ],
   "source": [
    "y_labels = []       # Trạng thái 165 ảnh\n",
    "\n",
    "# there are 15 people\n",
    "for person_id in range(1, 16):\n",
    "    for state in states:\n",
    "        y_labels.append(state)\n",
    "        # get name of each image file\n",
    "        fn = path + prefix + str(person_id).zfill(2) + '.' + state + surfix\n",
    "        \n",
    "        # open the file and read as grey image\n",
    "        tmp = cv2.imread(fn, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # then add image to dataset X\n",
    "        X[:, count] = tmp.reshape(D)\n",
    "        count += 1\n",
    "\n",
    "print(X)\n",
    "print(y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu thành tập train:test = 8:2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X.T)\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra với tỷ lệ 0.8:0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_scaled, y_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện bằng mô hình CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admind\\python\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - acc: 0.0713 - loss: 6.5354 - val_acc: 0.0303 - val_loss: 2.7890\n",
      "Epoch 2/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 902ms/step - acc: 0.1133 - loss: 2.9965 - val_acc: 0.0909 - val_loss: 2.4008\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 894ms/step - acc: 0.1050 - loss: 2.3885 - val_acc: 0.1212 - val_loss: 2.3988\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 889ms/step - acc: 0.1326 - loss: 2.3956 - val_acc: 0.0909 - val_loss: 2.4106\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 894ms/step - acc: 0.1376 - loss: 2.3866 - val_acc: 0.0606 - val_loss: 2.4351\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 879ms/step - acc: 0.1078 - loss: 2.3702 - val_acc: 0.0909 - val_loss: 2.4148\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 882ms/step - acc: 0.1043 - loss: 2.3753 - val_acc: 0.0909 - val_loss: 2.4553\n",
      "Epoch 8/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 888ms/step - acc: 0.1190 - loss: 2.3517 - val_acc: 0.0909 - val_loss: 2.4582\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 878ms/step - acc: 0.1479 - loss: 2.3266 - val_acc: 0.0606 - val_loss: 2.5208\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 885ms/step - acc: 0.1267 - loss: 2.3073 - val_acc: 0.0909 - val_loss: 2.5448\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your data is already loaded and preprocessed (X, y)\n",
    "# Reshape and normalize\n",
    "X_reshaped = X.reshape(-1, h, w, 1) / 255.0\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y_labels)\n",
    "y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
    "\n",
    "def gen_model(input_shape, num_classes):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        tf.keras.layers.Dropout(rate=0.15),\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Dropout(rate=0.1),\n",
    "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D(2,2),\n",
    "        tf.keras.layers.Dropout(rate=0.10),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# Adjust the input shape and number of classes\n",
    "model = gen_model((h, w, 1), len(np.unique(y_encoded)))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Tính độ chính xác của mô hình theo các độ đo Accuracy, Precision và Recall trên cả tập train và test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 160ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step \n",
      "Training Set Metrics:\n",
      "Accuracy: 0.25757575757575757\n",
      "Precision: 0.3480766019039136\n",
      "Recall: 0.24600399600399597\n",
      "\n",
      "Test Set Metrics:\n",
      "Accuracy: 0.09090909090909091\n",
      "Precision: 0.12599681020733652\n",
      "Recall: 0.16666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admind\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admind\\python\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Obtain model predictions\n",
    "y_pred_train_prob = model.predict(X_train)\n",
    "y_pred_test_prob = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_train = np.argmax(y_pred_train_prob, axis=1)\n",
    "y_pred_test = np.argmax(y_pred_test_prob, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels back to class labels\n",
    "y_true_train = np.argmax(y_train, axis=1)\n",
    "y_true_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"Training Set Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true_train, y_pred_train))\n",
    "print(\"Precision:\", precision_score(y_true_train, y_pred_train, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_true_train, y_pred_train, average='macro'))\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_true_test, y_pred_test))\n",
    "print(\"Precision:\", precision_score(y_true_test, y_pred_test, average='macro'))\n",
    "print(\"Recall:\", recall_score(y_true_test, y_pred_test, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Giải thích kết quả thu được:\n",
    "+ Theo tập train thì Accuracy khá thấp, tương ứng với Precision và Recall. Đây là mô hình khá tệ để thực hiện huấn luyện\n",
    "+ Để thực hiện test thì Accuracy còn thấp hơn nhiều, khoảng 6% dự đoán được kết quả. Đây là mô hình không tốt để thực hiện phân loại"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) So sánh kết quả khi giảm số chiều với mô hình ANN hoặc Logistic để phân loại "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Giảm chiều dữ liệu\n",
    "pca = PCA(n_components=100)\n",
    "X_reduced = pca.fit_transform(X.T)  # Chú ý là X.T vì chúng ta muốn các hàng của X là các mẫu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra với tỷ lệ 0.8:0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12121212121212122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admind\\python\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Phương pháp Multinomial Logistic Regression\n",
    "log_reg = LogisticRegression(multi_class='multinomial', max_iter=2000, solver=\"sag\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "print(f'Accuracy: {accuracy_log_reg}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kết quả có sự khác nhau:\n",
    "+ Nếu giảm số chiều rồi xử dụng mô hình Logistic Regression thì độ chính xác đạt 12%\n",
    "+ Trong khi nếu dùng mô hình CNN thì độ chính xác là 6%\n",
    "=> Mô hình huấn luyến khá tệ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Thực hiện các mô hình CNN và mô hình kết hợp PCA-ANN đã đề cập ở trên, đã được huấn luyện với toàn bộ tập dữ liệu, sau đó chạy dự đoán cho khoảng 05 ảnh chân dung bất kỳ có định dạng như bài thực hành phần ANN (kích thước 320x243, khuôn mặt người ở vị trí hơi lệch bên phải với chiều nhìn vào)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.06060606060606061\n"
     ]
    }
   ],
   "source": [
    "# Phương pháp ANN\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Khởi tạo mô hình ANN với 1 lớp ẩn có 100 nơ-ron\n",
    "ann_model = MLPClassifier(hidden_layer_sizes=(100,), random_state=42, max_iter=300)\n",
    "\n",
    "# Huấn luyện mô hình với tập dữ liệu huấn luyện\n",
    "ann_model.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán nhãn của tập dữ liệu kiểm tra\n",
    "y_pred = ann_model.predict(X_test)\n",
    "\n",
    "# Tính toán và in ra độ chính xác của mô hình trên tập kiểm tra\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phân loại ảnh\n",
    "import os\n",
    "folder_path = 'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week08\\\\data\\\\face_data\\\\'  \n",
    "\n",
    "num_images = 5\n",
    "\n",
    "new_height = 243\n",
    "new_width = 320\n",
    "\n",
    "X_face_random = np.zeros((new_height * new_width, num_images))\n",
    "\n",
    "for i in range(num_images):\n",
    "    image_name = f'Test{i+1}.png'\n",
    "    image_path = os.path.join(folder_path, image_name)\n",
    "    tmp = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    resized_image = cv2.resize(tmp, (new_width, new_height))\n",
    "    X_face_random[:, i] = resized_image.reshape(new_height * new_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dự đoán nhóm cho 5 ảnh mới: ['noglasses' 'leftlight' 'noglasses' 'leftlight' 'leftlight']\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Đường dẫn đến 5 ảnh chân dung mới\n",
    "image_paths = ['D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week08\\\\data\\\\face_data\\\\test1.png', \n",
    "               'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week08\\\\data\\\\face_data\\\\test1.png', \n",
    "               'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week08\\\\data\\\\face_data\\\\test1.png', \n",
    "               'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week08\\\\data\\\\face_data\\\\test1.png', \n",
    "               'D:\\\\Python\\\\MachineLearning\\\\MachineLearning\\\\week08\\\\data\\\\face_data\\\\test1.png', \n",
    "               ]\n",
    "processed_images = []\n",
    "\n",
    "for path in image_paths:\n",
    "    # Đọc ảnh và chỉnh sửa kích thước\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    resized_img = cv2.resize(img, (243, 320))\n",
    "    \n",
    "    # Làm phẳng ảnh và thêm vào danh sách\n",
    "    flattened_img = resized_img.flatten()\n",
    "    processed_images.append(flattened_img)\n",
    "\n",
    "# Chuyển danh sách ảnh thành một NumPy array và giảm chiều\n",
    "X_new = np.array(processed_images)\n",
    "X_new_reduced = pca.transform(X_new)  # Sử dụng PCA đã được fit trước đó\n",
    "\n",
    "# Dự đoán nhóm cho các ảnh mới\n",
    "predictions = log_reg.predict(X_new_reduced)\n",
    "print(\"Dự đoán nhóm cho 5 ảnh mới:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
